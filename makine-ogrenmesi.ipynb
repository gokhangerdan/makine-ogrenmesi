{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRISP-DM Metodolojisi (Cross-Industry Standard Process for Data Science)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[crisp-dm-metodolojisi-nedir](http://www.leylatilki.com/crisp-dm-metodolojisi-nedir/)\n",
    "\n",
    "[crisp-dm-hiyerarsik-surec-modeli](http://www.leylatilki.com/crisp-dm-hiyerarsik-surec-modeli/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## İçerik\n",
    "\n",
    "* [1. Veri Yükleme](#1.-Veri-Yükleme)\n",
    "* [2. Veri Ön İşleme](#2.-Veri-Ön-İşleme)\n",
    "    * [a. Eksik Veriler](#a.-Eksik-Veriler)\n",
    "    * [b. Kategorik Veriler](#b.-Kategorik-Veriler)\n",
    "    * [c. Verilerin Birleştirilmesi](#c.-Verilerin-Birleştirilmesi)\n",
    "    * [d. Veri Kümesinin Eğitim ve Test Olarak Bölünmesi](#d.-Veri-Kümesinin-Eğitim-ve-Test-Olarak-Bölünmesi)\n",
    "    * [e. Öznitelik Ölçekleme](#e.-Öznitelik-Ölçekleme)\n",
    "* [3. Basit Doğrusal Regresyon](#3.-Basit-Doğrusal-Regresyon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Veri Yükleme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ulke  boy  kilo   yas cinsiyet\n",
      "0    tr  130    30  10.0        e\n",
      "1    tr  125    36  11.0        e\n",
      "2    tr  135    34  10.0        k\n",
      "3    tr  133    30   9.0        k\n",
      "4    tr  129    38  12.0        e\n",
      "5    tr  180    90  30.0        e\n",
      "6    tr  190    80  25.0        e\n",
      "7    tr  175    90  35.0        e\n",
      "8    tr  177    60  22.0        k\n",
      "9    us  185   105  33.0        e\n",
      "10   us  165    55  27.0        k\n",
      "11   us  155    50  44.0        k\n",
      "12   us  160    58   NaN        k\n",
      "13   us  162    59  41.0        k\n",
      "14   us  167    62  55.0        k\n",
      "15   fr  174    70  47.0        e\n",
      "16   fr  193    90   NaN        e\n",
      "17   fr  187    80  27.0        e\n",
      "18   fr  183    88  28.0        e\n",
      "19   fr  159    40  29.0        k\n",
      "20   fr  164    66  32.0        k\n",
      "21   fr  166    56  42.0        k\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# csv formatındaki verisetini yüklemek için:\n",
    "veriler = pd.read_csv('veriler/eksikveriler.csv')\n",
    "\n",
    "# İlk 5 satırı ekrana yazdırmak için;\n",
    "print(veriler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Veri Ön İşleme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Veri**\n",
    "    * **Kategorik**\n",
    "        * Nominal\n",
    "            * *Binominal*\n",
    "            * *Polinominal*\n",
    "        * Ordinal\n",
    "    * **Sayısal**\n",
    "        * Oransal\n",
    "        * Aralık"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Eksik Veriler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sklearn.impute.SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[130.  30.  10.]\n",
      " [125.  36.  11.]\n",
      " [135.  34.  10.]\n",
      " [133.  30.   9.]\n",
      " [129.  38.  12.]\n",
      " [180.  90.  30.]\n",
      " [190.  80.  25.]\n",
      " [175.  90.  35.]\n",
      " [177.  60.  22.]\n",
      " [185. 105.  33.]\n",
      " [165.  55.  27.]\n",
      " [155.  50.  44.]\n",
      " [160.  58.  nan]\n",
      " [162.  59.  41.]\n",
      " [167.  62.  55.]\n",
      " [174.  70.  47.]\n",
      " [193.  90.  nan]\n",
      " [187.  80.  27.]\n",
      " [183.  88.  28.]\n",
      " [159.  40.  29.]\n",
      " [164.  66.  32.]\n",
      " [166.  56.  42.]]\n"
     ]
    }
   ],
   "source": [
    "sayisal_veriler = veriler.iloc[:,1:4].values\n",
    "\n",
    "print(sayisal_veriler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[130.    30.    10.  ]\n",
      " [125.    36.    11.  ]\n",
      " [135.    34.    10.  ]\n",
      " [133.    30.     9.  ]\n",
      " [129.    38.    12.  ]\n",
      " [180.    90.    30.  ]\n",
      " [190.    80.    25.  ]\n",
      " [175.    90.    35.  ]\n",
      " [177.    60.    22.  ]\n",
      " [185.   105.    33.  ]\n",
      " [165.    55.    27.  ]\n",
      " [155.    50.    44.  ]\n",
      " [160.    58.    28.45]\n",
      " [162.    59.    41.  ]\n",
      " [167.    62.    55.  ]\n",
      " [174.    70.    47.  ]\n",
      " [193.    90.    28.45]\n",
      " [187.    80.    27.  ]\n",
      " [183.    88.    28.  ]\n",
      " [159.    40.    29.  ]\n",
      " [164.    66.    32.  ]\n",
      " [166.    56.    42.  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "imputer = imputer.fit(sayisal_veriler[:,1:4])\n",
    "\n",
    "sayisal_veriler[:,1:4] = imputer.transform(sayisal_veriler[:,1:4])\n",
    "\n",
    "print(sayisal_veriler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Kategorik Veriler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[label-encoder-vs-one-hot-encoder](http://www.leylatilki.com/label-encoder-vs-one-hot-encoder/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "ulkeler = veriler.iloc[:,0:1].values\n",
    "\n",
    "ulkeler[:,0] = le.fit_transform(ulkeler[:,0])\n",
    "\n",
    "print(ulkeler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "ulkeler = veriler.iloc[:,0:1].values\n",
    "\n",
    "ulkeler = ohe.fit_transform(ulkeler).toarray()\n",
    "\n",
    "print(ulkeler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Verilerin Birleştirilmesi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)\n",
    "\n",
    "[pandas.concat](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fr   tr   us\n",
      "0   0.0  1.0  0.0\n",
      "1   0.0  1.0  0.0\n",
      "2   0.0  1.0  0.0\n",
      "3   0.0  1.0  0.0\n",
      "4   0.0  1.0  0.0\n",
      "5   0.0  1.0  0.0\n",
      "6   0.0  1.0  0.0\n",
      "7   0.0  1.0  0.0\n",
      "8   0.0  1.0  0.0\n",
      "9   0.0  0.0  1.0\n",
      "10  0.0  0.0  1.0\n",
      "11  0.0  0.0  1.0\n",
      "12  0.0  0.0  1.0\n",
      "13  0.0  0.0  1.0\n",
      "14  0.0  0.0  1.0\n",
      "15  1.0  0.0  0.0\n",
      "16  1.0  0.0  0.0\n",
      "17  1.0  0.0  0.0\n",
      "18  1.0  0.0  0.0\n",
      "19  1.0  0.0  0.0\n",
      "20  1.0  0.0  0.0\n",
      "21  1.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "ulkeler = pd.DataFrame(data = ulkeler, index=range(22), columns=['fr', 'tr', 'us'])\n",
    "\n",
    "print(ulkeler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      boy   kilo    yas\n",
      "0   130.0   30.0  10.00\n",
      "1   125.0   36.0  11.00\n",
      "2   135.0   34.0  10.00\n",
      "3   133.0   30.0   9.00\n",
      "4   129.0   38.0  12.00\n",
      "5   180.0   90.0  30.00\n",
      "6   190.0   80.0  25.00\n",
      "7   175.0   90.0  35.00\n",
      "8   177.0   60.0  22.00\n",
      "9   185.0  105.0  33.00\n",
      "10  165.0   55.0  27.00\n",
      "11  155.0   50.0  44.00\n",
      "12  160.0   58.0  28.45\n",
      "13  162.0   59.0  41.00\n",
      "14  167.0   62.0  55.00\n",
      "15  174.0   70.0  47.00\n",
      "16  193.0   90.0  28.45\n",
      "17  187.0   80.0  27.00\n",
      "18  183.0   88.0  28.00\n",
      "19  159.0   40.0  29.00\n",
      "20  164.0   66.0  32.00\n",
      "21  166.0   56.0  42.00\n"
     ]
    }
   ],
   "source": [
    "sayisal_veriler = pd.DataFrame(data = sayisal_veriler, index = range(22), columns = ['boy', 'kilo', 'yas'])\n",
    "print(sayisal_veriler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cinsiyet\n",
      "0         e\n",
      "1         e\n",
      "2         k\n",
      "3         k\n",
      "4         e\n",
      "5         e\n",
      "6         e\n",
      "7         e\n",
      "8         k\n",
      "9         e\n",
      "10        k\n",
      "11        k\n",
      "12        k\n",
      "13        k\n",
      "14        k\n",
      "15        e\n",
      "16        e\n",
      "17        e\n",
      "18        e\n",
      "19        k\n",
      "20        k\n",
      "21        k\n"
     ]
    }
   ],
   "source": [
    "cinsiyetler = veriler.iloc[:,-1:].values\n",
    "\n",
    "cinsiyetler = pd.DataFrame(data = cinsiyetler, index = range(22), columns=['cinsiyet'])\n",
    "\n",
    "print(cinsiyetler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fr   tr   us    boy   kilo    yas\n",
      "0   0.0  1.0  0.0  130.0   30.0  10.00\n",
      "1   0.0  1.0  0.0  125.0   36.0  11.00\n",
      "2   0.0  1.0  0.0  135.0   34.0  10.00\n",
      "3   0.0  1.0  0.0  133.0   30.0   9.00\n",
      "4   0.0  1.0  0.0  129.0   38.0  12.00\n",
      "5   0.0  1.0  0.0  180.0   90.0  30.00\n",
      "6   0.0  1.0  0.0  190.0   80.0  25.00\n",
      "7   0.0  1.0  0.0  175.0   90.0  35.00\n",
      "8   0.0  1.0  0.0  177.0   60.0  22.00\n",
      "9   0.0  0.0  1.0  185.0  105.0  33.00\n",
      "10  0.0  0.0  1.0  165.0   55.0  27.00\n",
      "11  0.0  0.0  1.0  155.0   50.0  44.00\n",
      "12  0.0  0.0  1.0  160.0   58.0  28.45\n",
      "13  0.0  0.0  1.0  162.0   59.0  41.00\n",
      "14  0.0  0.0  1.0  167.0   62.0  55.00\n",
      "15  1.0  0.0  0.0  174.0   70.0  47.00\n",
      "16  1.0  0.0  0.0  193.0   90.0  28.45\n",
      "17  1.0  0.0  0.0  187.0   80.0  27.00\n",
      "18  1.0  0.0  0.0  183.0   88.0  28.00\n",
      "19  1.0  0.0  0.0  159.0   40.0  29.00\n",
      "20  1.0  0.0  0.0  164.0   66.0  32.00\n",
      "21  1.0  0.0  0.0  166.0   56.0  42.00\n"
     ]
    }
   ],
   "source": [
    "egitim_verisi = pd.concat([ulkeler, sayisal_veriler], axis=1)\n",
    "\n",
    "print(egitim_verisi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fr   tr   us    boy   kilo    yas cinsiyet\n",
      "0   0.0  1.0  0.0  130.0   30.0  10.00        e\n",
      "1   0.0  1.0  0.0  125.0   36.0  11.00        e\n",
      "2   0.0  1.0  0.0  135.0   34.0  10.00        k\n",
      "3   0.0  1.0  0.0  133.0   30.0   9.00        k\n",
      "4   0.0  1.0  0.0  129.0   38.0  12.00        e\n",
      "5   0.0  1.0  0.0  180.0   90.0  30.00        e\n",
      "6   0.0  1.0  0.0  190.0   80.0  25.00        e\n",
      "7   0.0  1.0  0.0  175.0   90.0  35.00        e\n",
      "8   0.0  1.0  0.0  177.0   60.0  22.00        k\n",
      "9   0.0  0.0  1.0  185.0  105.0  33.00        e\n",
      "10  0.0  0.0  1.0  165.0   55.0  27.00        k\n",
      "11  0.0  0.0  1.0  155.0   50.0  44.00        k\n",
      "12  0.0  0.0  1.0  160.0   58.0  28.45        k\n",
      "13  0.0  0.0  1.0  162.0   59.0  41.00        k\n",
      "14  0.0  0.0  1.0  167.0   62.0  55.00        k\n",
      "15  1.0  0.0  0.0  174.0   70.0  47.00        e\n",
      "16  1.0  0.0  0.0  193.0   90.0  28.45        e\n",
      "17  1.0  0.0  0.0  187.0   80.0  27.00        e\n",
      "18  1.0  0.0  0.0  183.0   88.0  28.00        e\n",
      "19  1.0  0.0  0.0  159.0   40.0  29.00        k\n",
      "20  1.0  0.0  0.0  164.0   66.0  32.00        k\n",
      "21  1.0  0.0  0.0  166.0   56.0  42.00        k\n"
     ]
    }
   ],
   "source": [
    "sonuc = pd.concat([egitim_verisi, cinsiyetler], axis=1)\n",
    "\n",
    "print(sonuc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Veri Kümesinin Eğitim ve Test Olarak Bölünmesi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sklearn.model_selection.train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train\n",
      "     fr   tr   us    boy   kilo    yas\n",
      "8   0.0  1.0  0.0  177.0   60.0  22.00\n",
      "6   0.0  1.0  0.0  190.0   80.0  25.00\n",
      "16  1.0  0.0  0.0  193.0   90.0  28.45\n",
      "4   0.0  1.0  0.0  129.0   38.0  12.00\n",
      "2   0.0  1.0  0.0  135.0   34.0  10.00\n",
      "5   0.0  1.0  0.0  180.0   90.0  30.00\n",
      "17  1.0  0.0  0.0  187.0   80.0  27.00\n",
      "9   0.0  0.0  1.0  185.0  105.0  33.00\n",
      "7   0.0  1.0  0.0  175.0   90.0  35.00\n",
      "18  1.0  0.0  0.0  183.0   88.0  28.00\n",
      "3   0.0  1.0  0.0  133.0   30.0   9.00\n",
      "0   0.0  1.0  0.0  130.0   30.0  10.00\n",
      "15  1.0  0.0  0.0  174.0   70.0  47.00\n",
      "12  0.0  0.0  1.0  160.0   58.0  28.45\n",
      "\n",
      "x_test\n",
      "     fr   tr   us    boy  kilo   yas\n",
      "20  1.0  0.0  0.0  164.0  66.0  32.0\n",
      "10  0.0  0.0  1.0  165.0  55.0  27.0\n",
      "14  0.0  0.0  1.0  167.0  62.0  55.0\n",
      "13  0.0  0.0  1.0  162.0  59.0  41.0\n",
      "1   0.0  1.0  0.0  125.0  36.0  11.0\n",
      "21  1.0  0.0  0.0  166.0  56.0  42.0\n",
      "11  0.0  0.0  1.0  155.0  50.0  44.0\n",
      "19  1.0  0.0  0.0  159.0  40.0  29.0\n",
      "\n",
      "y_train\n",
      "   cinsiyet\n",
      "8         k\n",
      "6         e\n",
      "16        e\n",
      "4         e\n",
      "2         k\n",
      "5         e\n",
      "17        e\n",
      "9         e\n",
      "7         e\n",
      "18        e\n",
      "3         k\n",
      "0         e\n",
      "15        e\n",
      "12        k\n",
      "\n",
      "y_test\n",
      "   cinsiyet\n",
      "20        k\n",
      "10        k\n",
      "14        k\n",
      "13        k\n",
      "1         e\n",
      "21        k\n",
      "11        k\n",
      "19        k\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(egitim_verisi, cinsiyetler, test_size=0.33, random_state=0)\n",
    "\n",
    "print('x_train')\n",
    "print(x_train)\n",
    "print('\\nx_test')\n",
    "print(x_test)\n",
    "print('\\ny_train')\n",
    "print(y_train)\n",
    "print('\\ny_test')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Öznitelik Ölçekleme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standartlaştırma**\n",
    "\n",
    "\\begin{equation*}\n",
    "z=\\frac{x-\\mu}{\\sigma}\n",
    "\\end{equation*}\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "x:sayı && \\mu:ortalama & değer && \\sigma:standart & sapma\n",
    "\\end{eqnarray}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalleştirme**\n",
    "\n",
    "\\begin{equation*}\n",
    "z = \\frac{x-min(x)}{[max(x)-min(x)]}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      "[[-0.63245553  0.8660254  -0.40824829  0.45049444 -0.29657884 -0.24717129]\n",
      " [-0.63245553  0.8660254  -0.40824829  1.00824945  0.5096549   0.03416189]\n",
      " [ 1.58113883 -1.15470054 -0.40824829  1.13696215  0.91277178  0.35769504]\n",
      " [-0.63245553  0.8660254  -0.40824829 -1.6089087  -1.18343596 -1.18494855]\n",
      " [-0.63245553  0.8660254  -0.40824829 -1.35148331 -1.34468271 -1.372504  ]\n",
      " [-0.63245553  0.8660254  -0.40824829  0.57920713  0.91277178  0.50305051]\n",
      " [ 1.58113883 -1.15470054 -0.40824829  0.87953676  0.5096549   0.22171734]\n",
      " [-0.63245553 -1.15470054  2.44948974  0.79372829  1.51744708  0.78438369]\n",
      " [-0.63245553  0.8660254  -0.40824829  0.36468597  0.91277178  0.97193914]\n",
      " [ 1.58113883 -1.15470054 -0.40824829  0.70791983  0.8321484   0.31549506]\n",
      " [-0.63245553  0.8660254  -0.40824829 -1.43729177 -1.50592946 -1.46628173]\n",
      " [-0.63245553  0.8660254  -0.40824829 -1.56600447 -1.50592946 -1.372504  ]\n",
      " [ 1.58113883 -1.15470054 -0.40824829  0.32178174  0.10653803  2.09727185]\n",
      " [-0.63245553 -1.15470054  2.44948974 -0.27887751 -0.37720222  0.35769504]]\n",
      "\n",
      "X_test\n",
      "[[ 1.29099445 -0.37796447 -1.          0.47240026  1.32853794 -0.24991255]\n",
      " [-0.77459667 -0.37796447  1.          0.54952683  0.20439045 -0.64977262]\n",
      " [-0.77459667 -0.37796447  1.          0.70377998  0.91975703  1.58944379]\n",
      " [-0.77459667 -0.37796447  1.          0.31814711  0.61317136  0.46983559]\n",
      " [-0.77459667  2.64575131 -1.         -2.53553608 -1.73731884 -1.92932485]\n",
      " [ 1.29099445 -0.37796447 -1.          0.6266534   0.30658568  0.5498076 ]\n",
      " [-0.77459667 -0.37796447  1.         -0.2217389  -0.30658568  0.70975163]\n",
      " [ 1.29099445 -0.37796447 -1.          0.08676739 -1.32853794 -0.48982859]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(x_train)\n",
    "X_test = sc.fit_transform(x_test)\n",
    "\n",
    "print('X_train')\n",
    "print(X_train)\n",
    "print('\\nX_test')\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basit Doğrusal Regresyon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "y=ax+b\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Aylar  Satislar\n",
      "0       8   19671.5\n",
      "1      10   23102.5\n",
      "2      11   18865.5\n",
      "3      13   21762.5\n",
      "4      14   19945.5\n",
      "5      19   28321.0\n",
      "6      19   30075.0\n",
      "7      20   27222.5\n",
      "8      20   32222.5\n",
      "9      24   28594.5\n",
      "10     25   31609.0\n",
      "11     25   27897.0\n",
      "12     25   28478.5\n",
      "13     26   28540.5\n",
      "14     29   30555.5\n",
      "15     31   33969.0\n",
      "16     32   33014.5\n",
      "17     34   41544.0\n",
      "18     37   40681.5\n",
      "19     37   46970.0\n",
      "20     42   45869.0\n",
      "21     44   49136.5\n",
      "22     49   50651.0\n",
      "23     50   56906.0\n",
      "24     54   54715.5\n",
      "25     55   52791.0\n",
      "26     59   58484.5\n",
      "27     59   56317.5\n",
      "28     64   61195.5\n",
      "29     65   60936.0\n"
     ]
    }
   ],
   "source": [
    "satis_verileri = pd.read_csv('veriler/satislar.csv')\n",
    "\n",
    "print(satis_verileri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aylar\n",
      "    Aylar\n",
      "0       8\n",
      "1      10\n",
      "2      11\n",
      "3      13\n",
      "4      14\n",
      "5      19\n",
      "6      19\n",
      "7      20\n",
      "8      20\n",
      "9      24\n",
      "10     25\n",
      "11     25\n",
      "12     25\n",
      "13     26\n",
      "14     29\n",
      "15     31\n",
      "16     32\n",
      "17     34\n",
      "18     37\n",
      "19     37\n",
      "20     42\n",
      "21     44\n",
      "22     49\n",
      "23     50\n",
      "24     54\n",
      "25     55\n",
      "26     59\n",
      "27     59\n",
      "28     64\n",
      "29     65\n",
      "\n",
      "satislar\n",
      "    Satislar\n",
      "0    19671.5\n",
      "1    23102.5\n",
      "2    18865.5\n",
      "3    21762.5\n",
      "4    19945.5\n",
      "5    28321.0\n",
      "6    30075.0\n",
      "7    27222.5\n",
      "8    32222.5\n",
      "9    28594.5\n",
      "10   31609.0\n",
      "11   27897.0\n",
      "12   28478.5\n",
      "13   28540.5\n",
      "14   30555.5\n",
      "15   33969.0\n",
      "16   33014.5\n",
      "17   41544.0\n",
      "18   40681.5\n",
      "19   46970.0\n",
      "20   45869.0\n",
      "21   49136.5\n",
      "22   50651.0\n",
      "23   56906.0\n",
      "24   54715.5\n",
      "25   52791.0\n",
      "26   58484.5\n",
      "27   56317.5\n",
      "28   61195.5\n",
      "29   60936.0\n"
     ]
    }
   ],
   "source": [
    "aylar = satis_verileri[['Aylar']]\n",
    "\n",
    "satislar = satis_verileri[['Satislar']]\n",
    "\n",
    "print('aylar')\n",
    "print(aylar)\n",
    "print('\\nsatislar')\n",
    "print(satislar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train\n",
      "    Aylar\n",
      "5      19\n",
      "16     32\n",
      "8      20\n",
      "14     29\n",
      "23     50\n",
      "20     42\n",
      "1      10\n",
      "29     65\n",
      "6      19\n",
      "4      14\n",
      "18     37\n",
      "19     37\n",
      "9      24\n",
      "7      20\n",
      "25     55\n",
      "3      13\n",
      "0       8\n",
      "21     44\n",
      "15     31\n",
      "12     25\n",
      "\n",
      "x_test\n",
      "    Aylar\n",
      "2      11\n",
      "28     64\n",
      "13     26\n",
      "10     25\n",
      "26     59\n",
      "24     54\n",
      "27     59\n",
      "11     25\n",
      "17     34\n",
      "22     49\n",
      "\n",
      "y_train\n",
      "    Satislar\n",
      "5    28321.0\n",
      "16   33014.5\n",
      "8    32222.5\n",
      "14   30555.5\n",
      "23   56906.0\n",
      "20   45869.0\n",
      "1    23102.5\n",
      "29   60936.0\n",
      "6    30075.0\n",
      "4    19945.5\n",
      "18   40681.5\n",
      "19   46970.0\n",
      "9    28594.5\n",
      "7    27222.5\n",
      "25   52791.0\n",
      "3    21762.5\n",
      "0    19671.5\n",
      "21   49136.5\n",
      "15   33969.0\n",
      "12   28478.5\n",
      "\n",
      "y_test\n",
      "    Satislar\n",
      "2    18865.5\n",
      "28   61195.5\n",
      "13   28540.5\n",
      "10   31609.0\n",
      "26   58484.5\n",
      "24   54715.5\n",
      "27   56317.5\n",
      "11   27897.0\n",
      "17   41544.0\n",
      "22   50651.0\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(aylar, satislar, test_size=0.33, random_state=0)\n",
    "\n",
    "print('x_train')\n",
    "print(x_train)\n",
    "print('\\nx_test')\n",
    "print(x_test)\n",
    "print('\\ny_train')\n",
    "print(y_train)\n",
    "print('\\ny_test')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      "[[-0.70368853]\n",
      " [ 0.15126015]\n",
      " [-0.63792324]\n",
      " [-0.0460357 ]\n",
      " [ 1.33503524]\n",
      " [ 0.80891298]\n",
      " [-1.29557607]\n",
      " [ 2.32151449]\n",
      " [-0.70368853]\n",
      " [-1.03251494]\n",
      " [ 0.48008657]\n",
      " [ 0.48008657]\n",
      " [-0.37486211]\n",
      " [-0.63792324]\n",
      " [ 1.66386166]\n",
      " [-1.09828023]\n",
      " [-1.42710664]\n",
      " [ 0.94044355]\n",
      " [ 0.08549487]\n",
      " [-0.30909683]]\n",
      "\n",
      "X_test\n",
      "[[-1.68268756]\n",
      " [ 1.33023274]\n",
      " [-0.82997427]\n",
      " [-0.88682182]\n",
      " [ 1.04599497]\n",
      " [ 0.76175721]\n",
      " [ 1.04599497]\n",
      " [-0.88682182]\n",
      " [-0.37519385]\n",
      " [ 0.47751944]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "X_train = sc.fit_transform(x_train)\n",
    "X_test = sc.fit_transform(x_test)\n",
    "\n",
    "print('X_train')\n",
    "print(X_train)\n",
    "print('\\nX_test')\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
